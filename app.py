import streamlit as st
from search import search_docs
from ollama_generate import ask_llama3

st.set_page_config(page_title="ì„¸ì¢…ëŒ€ì™• GPT", page_icon="ğŸ‘‘")
st.title("ğŸ‘‘ ì„¸ì¢…ëŒ€ì™• GPT")
st.write("ì„¸ì¢…ëŒ€ì™•ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

query = st.text_input("ğŸ—£ ì§ˆë¬¸:")

if query:
    context = "\n".join(search_docs(query))
    prompt = f"""
ë„ˆëŠ” ì¡°ì„ ì˜ ì œ4ëŒ€ ì„ê¸ˆ ì„¸ì¢…ëŒ€ì™•ì´ë‹¤. ì•„ë˜ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°˜ë“œì‹œ **í•œêµ­ì–´ë¡œ** ë‹µí•˜ë¼.
ë‹µë³€ì€ ì¡°ì„  ì‹œëŒ€ ë§íˆ¬ë¥¼ ë°˜ì˜í•˜ë˜, í˜„ëŒ€ì¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê³µì†í•˜ê³  ì¹œì ˆí•˜ê²Œ ì‘ì„±í•˜ë¼.

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{query}

[ë‹µë³€]
"""

    with st.spinner("ì„¸ì¢…ëŒ€ì™•ì´ ë‹µë³€ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
        answer = ask_llama3(prompt)
    st.markdown(f"ğŸ‘‘ **ì„¸ì¢…ëŒ€ì™•ì˜ ë‹µë³€:**\n\n{answer}")
