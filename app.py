import streamlit as st
from search import search_docs
from ollama_generate import ask_llama3

# ì§ˆë¬¸/ë‹µë³€ íˆìŠ¤í† ë¦¬ ì €ì¥ìš© ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state.history = []

st.set_page_config(page_title="ì„¸ì¢…ëŒ€ì™• GPT", page_icon="ğŸ‘‘")

# ì‚¬ì´ë“œë°”ì— ì˜ˆì‹œ ì§ˆë¬¸
with st.sidebar:
    st.markdown("### ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ")
    st.markdown("""
- ì„¸ì¢…ëŒ€ì™•ì€ ëˆ„êµ¬ì¸ê°€ìš”?
- í›ˆë¯¼ì •ìŒì€ ì™œ ë§Œë“¤ì—ˆë‚˜ìš”?
- ì¥ì˜ì‹¤ì„ ì–´ë–»ê²Œ ìƒê°í•˜ë‚˜ìš”?
- ì„¸ì¢…ëŒ€ì™•ì˜ ì—…ì ì€?
""")

# íƒ€ì´í‹€
st.title("ğŸ‘‘ ì„¸ì¢…ëŒ€ì™• GPT")
st.write("ì„¸ì¢…ëŒ€ì™•ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

# ì§ˆë¬¸ ì…ë ¥
query = st.text_input("ğŸ—£ ì§ˆë¬¸:")

# ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("ì§ˆë¬¸í•˜ê¸°") and query:
    context = "\n".join(search_docs(query))
    prompt = f"""
ë„ˆëŠ” ì¡°ì„ ì˜ ì œ4ëŒ€ ì„ê¸ˆ ì„¸ì¢…ëŒ€ì™•ì´ë‹¤. ì•„ë˜ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¡°ì„ ì‹œëŒ€ ë§íˆ¬ì™€ ì² í•™ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ë¼. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µí•˜ë¼.

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{query}

[ë‹µë³€]
"""

    with st.spinner("ğŸ‘‘ ì„¸ì¢…ëŒ€ì™•ì´ ë‹µë³€ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
        answer = ask_llama3(prompt)

    # íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state.history.append((query, answer))

# ì¶œë ¥ ì„¹ì…˜
st.markdown("---")
for q, a in reversed(st.session_state.history):
    st.markdown(f"<p style='font-size:16px;'>ğŸ—£ <b>ì§ˆë¬¸:</b> {q}</p>", unsafe_allow_html=True)
    st.markdown(f"<p style='font-size:16px;'>ğŸ‘‘ <b>ì„¸ì¢…ëŒ€ì™•ì˜ ë‹µë³€:</b> {a}</p>", unsafe_allow_html=True)
    st.markdown("<hr>", unsafe_allow_html=True)
